# Config file for ReBench
# Config format is YAML (see http://yaml.org/ for detailed spec)

# this experiment is chosen if no parameter is given to rebench
default_experiment: Test
default_data_file:  'tests/test.data'

# reporting should enable the configuration of the format of the output
# reporting:
    # results can also be reported to a codespeed instance
    # see: https://github.com/tobami/codespeed
    # codespeed:
    #     url: http://localhost:8000/result/add-multiple/
    #     project: test
    #     # other details like commitid are required to be given as parameters

# general configuration for runs
runs:
    min_iteration_time:     800    # give a warning if average runtime is below this value

    # to avoid increased measurement errors by interference between parallel
    # runs, increase this number, but be aware it reduces the number of
    # parallel executed benchmarks
    # Note: this is a strictly global setting
    parallel_interference_factor: 2.5

# definition of benchmark suites
# settings in the benchmark suite will be overridden by similar settings of the executor
benchmark_suites:
    TestSuite1:
        gauge_adapter: TestExecutor
        # location: /Users/...
        command: TestBenchMarks %(benchmark)s %(input)s %(variable)s
        input_sizes: [2, 10]
        benchmarks:
            - Bench1
            - Bench2:
                extra_args: 6
        max_invocation_time: 1 # specifies the maximum runtime in seconds
        variable_values: # this is an other dimension, over which the runs need to be varied
            - val1
            - val2
    TestSuite2:
        gauge_adapter: TestExecutor
        command: TestBenchMarks %(benchmark)s %(input)s %(variable)s
        input_sizes: [100, 1000]
        cores: [7, 13]
        benchmarks:
            - Bench1:
                extra_args: "%(cores)s 3000"
            - Bench2
    TestBrokenCommandFormatSuite:
        gauge_adapter: TestExecutor
        command: TestBenchMarks %(benchmark) %(input) %(variable) # conversion is not indicated, needs to be %(benchmark)s to indicate string conversion
        input_sizes: [100, 1000]
        cores: [7, 13]
        benchmarks: [Bench1]
    TestBrokenCommandFormatSuite2:
        gauge_adapter: TestExecutor
        command: " %(benchmark) -i 3000s " # conversion is not indicated, needs to be %(benchmark)s to indicate string conversion
        input_sizes: [1]
        cores: [1]
        benchmarks: [Bench1]

# executors have a name and are specified by a path and the executable to be executed
# optional: the number of cores for which the runs have to be executed
executors:
    TestRunner1:
        path: tests
        executable: test-vm1.py %(cores)s
        cores: [1, 4]
        ## This requests ReBench to execute all benchmarks on this executor without
        ## any other benchmarks in parallel.
        ## true is the standard setting
        execute_exclusively: false

    TestRunner2:
        path: tests
        executable: test-vm2.py
        ## This requests ReBench to execute all benchmarks on this executor without
        ## any other benchmarks in parallel.
        ## true is the standard setting
        execute_exclusively: false

# define the benchmarks to be executed for a re-executable benchmark run
# special definitions done here should override benchmark suite definitions, and
# executor definitions
experiments:
    Test:
        description: >
            This run definition is used for testing.
            It should try all possible settings and the generated out
            will be compared to the expected one by the unit test(s)
        suites:
            - TestSuite1
            - TestSuite2
        data_file: TestTest.data.data
        executions:
            # List of executors and Benchmarks/Benchmark Suites to be run on them
            # benchmarks define here will override the ones defined for the whole run

            #the following example is equivalent to the global run definition,
            #but needs to be tested...
            - TestRunner1:
                suites:
                  - TestSuite1
                cores: [42]
            - TestRunner1:
                suites:
                  - TestSuite2
            - TestRunner2
    Test-variable-values:
        description: to test for a bug
        suites:
           - TestSuite2
        executions:
           - TestRunner2
    TestBrokenCommandFormat:
        description: to test for a proper error when conversions are not properly indicated in the config
        suites:
           - TestBrokenCommandFormatSuite
        executions:
           - TestRunner2
    TestBrokenCommandFormat2:
        description: to test for a proper error when conversions are not properly indicated in the config
        suites:
           - TestBrokenCommandFormatSuite2
        executions:
           - TestRunner2
